{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmCnkn64Wwkgm6dOv7K3k4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57173f4c12b04361990e16e3c9db7cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46135cc26514417b89482e514885af6c",
              "IPY_MODEL_00b99e0db01048feaae8568ba27463fd",
              "IPY_MODEL_791a21f96ddc4d188f513d369310b3e1"
            ],
            "layout": "IPY_MODEL_c272b2c65c674496a5fb9c688c704f0f"
          }
        },
        "46135cc26514417b89482e514885af6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55df3ce96eb044e8a2f04d9aafee759a",
            "placeholder": "​",
            "style": "IPY_MODEL_1a61b69e63cf434b9b065002761bcbb5",
            "value": ""
          }
        },
        "00b99e0db01048feaae8568ba27463fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e4fdce69e94ff3a3a4284d35ad6a0d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c04b916058940ef86546b24688855e4",
            "value": 1
          }
        },
        "791a21f96ddc4d188f513d369310b3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e27a7d2ac1a4672a7ba3f671cedf2e6",
            "placeholder": "​",
            "style": "IPY_MODEL_6173129e0dab49d1a823b6e50c85b330",
            "value": " 5/? [00:08&lt;00:00,  1.63s/it]"
          }
        },
        "c272b2c65c674496a5fb9c688c704f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55df3ce96eb044e8a2f04d9aafee759a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a61b69e63cf434b9b065002761bcbb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69e4fdce69e94ff3a3a4284d35ad6a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5c04b916058940ef86546b24688855e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e27a7d2ac1a4672a7ba3f671cedf2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6173129e0dab49d1a823b6e50c85b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheshboj/agenticai_basics/blob/Langchain_components/RAG_CHAT_BOT_EVALUATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install dependencies\n"
      ],
      "metadata": {
        "id": "3OvFxmGBy_Er"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHZdkVx8pS0K",
        "outputId": "1fed7ac0-ac87-4861-d197-0abfe586ba60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain langchain-community langchain-openai langchain-chroma pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU \"unstructured[all-docs]\""
      ],
      "metadata": {
        "id": "HpLyoWsy0buD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e44739c-1e3b-468b-fac6-bcfd09718225"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m614.4/981.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.1/529.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.9/207.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIOtASkc71nO",
        "outputId": "87ef8f7f-f49f-4a94-c448-31ee80afbe19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.8/411.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.7/343.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "AKSeb_tf8ZTT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environment variables"
      ],
      "metadata": {
        "id": "PKgxjPH8ay0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_APIKEY')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API')\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith_rag_tm_eval\""
      ],
      "metadata": {
        "id": "R8G3WiRTplsS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fWAk_jYb8W8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load documents (PDF example)"
      ],
      "metadata": {
        "id": "NNM4qZHYzIjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = TextLoader(\"/content/Tech_Mahindra_Report_original.md\")\n",
        "doc = loader.load()"
      ],
      "metadata": {
        "id": "uWK_xmBjz4FT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
        "\n",
        "loader = UnstructuredMarkdownLoader(\"/content/Tech_Mahindra_Report_original.md\", mode=\"elements\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "7TTwR-OM0A_6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWhkgyYj0tKc",
        "outputId": "b387f28e-afa3-442b-8671-259e15bb43f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Split into chunks"
      ],
      "metadata": {
        "id": "PxxjkbBkzXgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,      # Character chunks\n",
        "    chunk_overlap=200,    # Overlap for context\n",
        "    add_start_index=True  # Track source location\n",
        ")\n",
        "splits = text_splitter.split_documents(docs)\n",
        "print(f\"Split into {len(splits)} chunks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbAphjJwzOSh",
        "outputId": "123c7dbf-11ab-4b2c-b773-dcb623d04e7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 162 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Embeddings & Vector Store (Chroma - local, persistent)"
      ],
      "metadata": {
        "id": "rCEi3gC_0_cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # Fast/cheap embeddings\n",
        "\n",
        "# Filter complex metadata before creating the vectorstore\n",
        "filtered_splits = filter_complex_metadata(splits)\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=filtered_splits,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./techm_db\"  # Saves locally\n",
        ")"
      ],
      "metadata": {
        "id": "FkVQuk350-zw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Create retriever (k=4 most relevant docs)"
      ],
      "metadata": {
        "id": "ZqYzEznG2B02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "kibifrb12AHk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. RAG Chain: Retrieve → Prompt → LLM → Parse"
      ],
      "metadata": {
        "id": "YH6rgtu32Odj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langsmith import traceable\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the question based ONLY on the provided context.\n",
        "If you can't answer from context, say \"I don't have enough information.\"\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "# Chain: docs → text → prompt → LLM → string\n",
        "@traceable(run_type=\"chain\")\n",
        "def call_rag_chain(question: str) -> str:\n",
        "  rag_chain = (\n",
        "          RunnableParallel({\n",
        "          \"context\": retriever,\n",
        "          \"question\": RunnablePassthrough()\n",
        "      }) # Input → retrieve + pass-through\n",
        "      | prompt\n",
        "      | llm\n",
        "      | StrOutputParser()\n",
        "  )\n",
        "  answer = rag_chain.invoke(question)\n",
        "  print(f\"Q: {question}\\nA: {answer}\")\n",
        "  return answer"
      ],
      "metadata": {
        "id": "8L1FwWmO2NCE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJ6JScKm5Klm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test it!\n",
        "question = \"how many PTO we have?\"\n",
        "call_rag_chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5sWtSSjP3sIE",
        "outputId": "5600273d-e8c0-4735-a98d-0f6ae420bddb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: how many PTO we have?\n",
            "A: The total minimum PTO is approximately 35-40+ days, excluding comp off and extensions.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The total minimum PTO is approximately 35-40+ days, excluding comp off and extensions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "thread_id = uuid.uuid4()"
      ],
      "metadata": {
        "id": "K2AyE44nloBW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJaxgT6Elpiu",
        "outputId": "d5ac84ed-1eeb-4876-f343-0d303eec5645"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('126df524-72eb-4a3b-84d4-b011c1cd0fd4')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Test the bot!\n",
        "question = \"\"\n",
        "answer = call_rag_chain(question)\n",
        "# Interactive chat loop\n",
        "while True:\n",
        "    query = input(\"\\nAsk a question (or 'quit'): \")\n",
        "    if query.lower() == 'quit':\n",
        "        break\n",
        "    print(f\"A: {call_rag_chain(query,langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})}\")"
      ],
      "metadata": {
        "id": "sQgi30Nxum1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b45515-8c9a-446f-d36b-dc2d4c56d059"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: \n",
            "A: I don't have enough information.\n",
            "\n",
            "Ask a question (or 'quit'): what is total paid time off in techm\n",
            "Q: what is total paid time off in techm\n",
            "A: The total minimum paid time off (PTO) at Tech Mahindra is approximately 35-40+ days, excluding compensatory off and extensions.\n",
            "A: The total minimum paid time off (PTO) at Tech Mahindra is approximately 35-40+ days, excluding compensatory off and extensions.\n",
            "\n",
            "Ask a question (or 'quit'): qyit\n",
            "Q: qyit\n",
            "A: I don't have enough information.\n",
            "A: I don't have enough information.\n",
            "\n",
            "Ask a question (or 'quit'): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38d6c974",
        "outputId": "00faad38-a238-471c-dbb7-3ade93b20aa8"
      },
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 2. Define a ChatPromptTemplate named question_gen_prompt\n",
        "question_gen_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Generate a single question that can be answered SOLELY from the following context.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question:\n",
        "\"\"\")\n",
        "\n",
        "# 3. Initialize a ChatOpenAI model for generating questions\n",
        "question_gen_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# 4. Create an LLM chain named question_gen_chain\n",
        "question_gen_chain = (\n",
        "    {\"context\": lambda x: x}\n",
        "    | question_gen_prompt\n",
        "    | question_gen_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 5. Initialize an empty list called generated_questions\n",
        "generated_questions = []\n",
        "\n",
        "# 6. Iterate through each split and generate a question\n",
        "for i, split in enumerate(splits):\n",
        "    question = question_gen_chain.invoke(split.page_content)\n",
        "    generated_questions.append(question)\n",
        "    print(f\"Generated question for chunk {i+1}: {question}\")\n",
        "\n",
        "print(f\"\\nTotal {len(generated_questions)} questions generated.\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated question for chunk 1: What is the primary focus of Tech Mahindra's business operations?\n",
            "Generated question for chunk 2: What is the employee count mentioned in the context?\n",
            "Generated question for chunk 3: What is the primary focus of the report for Tech Mahindra Limited in December 2025?\n",
            "Generated question for chunk 4: What is the main purpose of the executive summary?\n",
            "Generated question for chunk 5: What is the number of professionals employed by Tech Mahindra?\n",
            "Generated question for chunk 6: What types of leave are included in the HR policies?\n",
            "Generated question for chunk 7: What are the current headcount and attrition rates of the workforce?\n",
            "Generated question for chunk 8: What is the name of the initiative focused on AI strategy and future roadmap?\n",
            "Generated question for chunk 9: What are the key components of the leave policy outlined in Section 1?\n",
            "Generated question for chunk 10: What type of leave is referred to as \"Earned Leave\"?\n",
            "Generated question for chunk 11: What is the maximum number of unused earned leave days that can be encashed during final settlement?\n",
            "Generated question for chunk 12: What are the different types of leave mentioned in the context?\n",
            "Generated question for chunk 13: How many days of advance leave are available?\n",
            "Generated question for chunk 14: Is there a formal casual leave policy at Tech Mahindra?\n",
            "Generated question for chunk 15: What is the condition under which an employee is eligible for Compensatory Off?\n",
            "Generated question for chunk 16: What options does an employee have if they have exhausted their leave balance?\n",
            "Generated question for chunk 17: How many public holidays are there per year?\n",
            "Generated question for chunk 18: What are the policies regarding maternity and paternity leave?\n",
            "Generated question for chunk 19: What is the maximum duration of maternity leave that can be taken at Tech Mahindra, including extensions?\n",
            "Generated question for chunk 20: What is the duration of paternity leave according to the provided context?\n",
            "Generated question for chunk 21: What are the additional leave benefits mentioned in section 1.4?\n",
            "Generated question for chunk 22: What types of reasons can Sabbatical Leave be taken for?\n",
            "Generated question for chunk 23: What are the benefits of flexible work-from-home arrangements?\n",
            "Generated question for chunk 24: What is the purpose of the flexible work arrangements mentioned in the context?\n",
            "Generated question for chunk 25: What is the summary of leave entitlements for annual leave?\n",
            "Generated question for chunk 26: What is the total minimum paid time off (PTO) available, excluding compensatory off and extensions?\n",
            "Generated question for chunk 27: What metrics are used to assess the employee count in the workforce?\n",
            "Generated question for chunk 28: What is the status of the current workforce as of December 2025?\n",
            "Generated question for chunk 29: What was the total headcount as of March 31, 2025?\n",
            "Generated question for chunk 30: What are some historical trends in the workforce?\n",
            "Generated question for chunk 31: What was the headcount on March 31, 2024?\n",
            "Generated question for chunk 32: What is the focus of the report titled \"2.3 Quarterly Headcount Movement (FY'25-26)\"?\n",
            "Generated question for chunk 33: What was the headcount at the end of Q1 FY'26?\n",
            "Generated question for chunk 34: What are the trends in IT headcount?\n",
            "Generated question for chunk 35: What was the IT headcount in Q2 FY'26?\n",
            "Generated question for chunk 36: What does the slight decline in IT headcount year-over-year suggest about the company's approach to staffing?\n",
            "Generated question for chunk 37: What is the attrition rate mentioned in the context?\n",
            "Generated question for chunk 38: What was the attrition rate in Q2 FY'26?\n",
            "Generated question for chunk 39: What is the current attrition rate mentioned in the analysis?\n",
            "Generated question for chunk 40: What is the focus of the section titled \"2.6 Workforce Economics\"?\n",
            "Generated question for chunk 41: What is the revenue per employee in INR?\n",
            "Generated question for chunk 42: What is the focus of section 2.7 in the document?\n",
            "Generated question for chunk 43: What is the geographic spread of the organization mentioned in the context?\n",
            "Generated question for chunk 44: What is the size of the workforce of professionals based in India?\n",
            "Generated question for chunk 45: What regions are identified as Global Centers?\n",
            "Generated question for chunk 46: What types of services are offered in the context provided?\n",
            "Generated question for chunk 47: What is the focus of Section 3 in the document?\n",
            "Generated question for chunk 48: What is the title of the strategic initiative mentioned in the context?\n",
            "Generated question for chunk 49: What is the name of Tech Mahindra's AI strategy launched in April 2025?\n",
            "Generated question for chunk 50: What is the purpose of the vision statement?\n",
            "Generated question for chunk 51: What are the key components needed to ensure AI delivers real-world impact?\n",
            "Generated question for chunk 52: Who is the CEO and Managing Director of Tech Mahindra?\n",
            "Generated question for chunk 53: What are the four foundational pillars of AI strategy?\n",
            "Generated question for chunk 54: What was delivered?\n",
            "Generated question for chunk 55: What is the primary focus of embedding AI into enterprise processes?\n",
            "Generated question for chunk 56: What are the potential benefits of unlocking new business models and customer experiences?\n",
            "Generated question for chunk 57: What is the primary goal of legacy system modernization in the context of AI-readiness?\n",
            "Generated question for chunk 58: What is the primary goal of implementing intelligent automation in a process?\n",
            "Generated question for chunk 59: What is the main focus of the section titled \"2. Productivity Delivered\"?\n",
            "Generated question for chunk 60: What is the primary focus of the initiatives mentioned in the context?\n",
            "Generated question for chunk 61: What are the key components of intelligent automation?\n",
            "Generated question for chunk 62: What is the primary goal of optimized spending in the context provided?\n",
            "Generated question for chunk 63: What are the primary goals of the operational excellence and cost optimization focus?\n",
            "Generated question for chunk 64: What is the title of the section that discusses innovation?\n",
            "Generated question for chunk 65: What is the focus of the context provided?\n",
            "Generated question for chunk 66: What technology is being utilized in the context provided?\n",
            "Generated question for chunk 67: What is the focus of the discussed context?\n",
            "Generated question for chunk 68: What are the key strategies for achieving competitive differentiation and market expansion?\n",
            "Generated question for chunk 69: What is the title of the section that discusses the delivery of assurance?\n",
            "Generated question for chunk 70: How can trust and governance be integrated into deployments?\n",
            "Generated question for chunk 71: What are the key components of responsible AI practices?\n",
            "Generated question for chunk 72: What are the primary processes involved in ensuring the accuracy of AI outcomes?\n",
            "Generated question for chunk 73: What are the primary considerations for ensuring ethical AI practices in compliance and risk mitigation?\n",
            "Generated question for chunk 74: What are the key AI technologies and frameworks discussed in section 3.3?\n",
            "Generated question for chunk 75: What is the name of India's first foundational Large Language Model (LLM) developed in collaboration with Intel Corporation?\n",
            "Generated question for chunk 76: What capabilities do Agentic AI systems possess that enable them to deliver tangible business value across industries?\n",
            "Generated question for chunk 77: What is the primary purpose of the VerifAI Framework?\n",
            "Generated question for chunk 78: What trio of digital technologies does ZeroOps, InfinityOps Solutions empower clients to harness?\n",
            "Generated question for chunk 79: What recent example demonstrates the delivery of Agentic AI in the context of pharmacovigilance?\n",
            "Generated question for chunk 80: What are the key focus areas of the industry mentioned in section 3.4?\n",
            "Generated question for chunk 81: Which sectors is Tech Mahindra's AI strategy targeting for significant transformation?\n",
            "Generated question for chunk 82: What are the key applications of AI in the Life Sciences and Healthcare industry?\n",
            "Generated question for chunk 83: What is the focus of the 3.5 Talent Development & AI Reskilling initiative?\n",
            "Generated question for chunk 84: What is the primary goal of the Workforce Upskilling Initiative?\n",
            "Generated question for chunk 85: What is the focus of section 3.6 in the document?\n",
            "Generated question for chunk 86: What types of organizations is Intel Corporation collaborating with for AI model deployment?\n",
            "Generated question for chunk 87: What does the Curated AI Partner Ecosystem ensure for optimal AI deployment?\n",
            "Generated question for chunk 88: What is the focus of section 3.7 in the document?\n",
            "Generated question for chunk 89: What recognition did the company receive in Avasant's Applied AI Services 2024?\n",
            "Generated question for chunk 90: What are the AI service offerings mentioned in section 3.8?\n",
            "Generated question for chunk 91: What types of services does Tech Mahindra offer in the field of AI?\n",
            "Generated question for chunk 92: What services are typically offered in AI strategy and consultation?\n",
            "Generated question for chunk 93: What are the key components involved in strategy development and roadmap creation?\n",
            "Generated question for chunk 94: What is the purpose of an AI maturity assessment?\n",
            "Generated question for chunk 95: What is the purpose of evaluating enterprise AI architecture?\n",
            "Generated question for chunk 96: What are the key considerations for successful AI implementation in organizations?\n",
            "Generated question for chunk 97: What are the key steps involved in the process of solution design and deployment?\n",
            "Generated question for chunk 98: What is the focus of the context provided?\n",
            "Generated question for chunk 99: What is the primary focus of legacy system modernization?\n",
            "Generated question for chunk 100: What does Responsible AI aim to ensure in the development and deployment of artificial intelligence systems?\n",
            "Generated question for chunk 101: What are governance frameworks?\n",
            "Generated question for chunk 102: What are some common risk mitigation strategies?\n",
            "Generated question for chunk 103: What are the key principles of compliance in ethical AI practices?\n",
            "Generated question for chunk 104: What are agentic AI systems?\n",
            "Generated question for chunk 105: What are autonomous decision-making workflows?\n",
            "Generated question for chunk 106: What are real-time execution platforms used for?\n",
            "Generated question for chunk 107: What is the significance of automation in a business context?\n",
            "Generated question for chunk 108: What are the key areas of focus for future opportunities outlined in Section 4?\n",
            "Generated question for chunk 109: What is the focus period mentioned in the context?\n",
            "Generated question for chunk 110: What is the expected outcome of the Workforce AI Reskilling initiative by March 2026?\n",
            "Generated question for chunk 111: What is the time frame of the Medium-term Strategy mentioned in the context?\n",
            "Generated question for chunk 112: What is the target percentage increase for AI services revenue?\n",
            "Generated question for chunk 113: What is the target number of AI/ML specialists that Talent Bench aims to build?\n",
            "Generated question for chunk 114: How many production agentic AI systems are being deployed?\n",
            "Generated question for chunk 115: What is the target number of AI-enabled customers to be expanded to?\n",
            "Generated question for chunk 116: What is the time frame for the long-term vision outlined in the context?\n",
            "Generated question for chunk 117: What is the primary focus of an AI-first organization?\n",
            "Generated question for chunk 118: What is the goal of the industry leadership initiative mentioned in the context?\n",
            "Generated question for chunk 119: What percentage of internal processes are driven by AI in autonomous workflows?\n",
            "Generated question for chunk 120: What type of frameworks and solutions does the context focus on developing?\n",
            "Generated question for chunk 121: What are the strategic priorities outlined in section 4.4?\n",
            "Generated question for chunk 122: What are the key priorities emphasized in the context of Responsible AI?\n",
            "Generated question for chunk 123: What type of solutions does the context emphasize for addressing industry needs?\n",
            "Generated question for chunk 124: What is the primary focus of agentic AI?\n",
            "Generated question for chunk 125: What model does the Ecosystem Play utilize?\n",
            "Generated question for chunk 126: What mindset is being promoted across the organization in the Talent & Culture context?\n",
            "Generated question for chunk 127: What are the main challenges and opportunities discussed in Section 5?\n",
            "Generated question for chunk 128: What are the current challenges mentioned in section 5.1?\n",
            "Generated question for chunk 129: What was the year-over-year change in headcount for IT services?\n",
            "Generated question for chunk 130: What are the main challenges faced by companies in the market due to competition and talent availability?\n",
            "Generated question for chunk 131: What challenges are businesses facing that affect their ability to realize revenue quickly?\n",
            "Generated question for chunk 132: What are the strategic opportunities identified in section 5.2?\n",
            "Generated question for chunk 133: What is the expected compound annual growth rate (CAGR) of the global GenAI market through 2030?\n",
            "Generated question for chunk 134: What industries are identified as ready for AI-driven transformation according to the context?\n",
            "Generated question for chunk 135: What is one strategy mentioned for building a proprietary AI framework?\n",
            "Generated question for chunk 136: What regions are targeted for the expansion of AI services?\n",
            "Generated question for chunk 137: What are the main points summarized in Section 6?\n",
            "Generated question for chunk 138: What guidelines should employees follow regarding workplace conduct?\n",
            "Generated question for chunk 139: What benefits does the company offer for maternity and paternity leave?\n",
            "Generated question for chunk 140: What is the primary audience targeted by the provided context?\n",
            "Generated question for chunk 141: What is the focus of Project Indus in relation to market trends?\n",
            "Generated question for chunk 142: What is the primary focus of the provided context?\n",
            "Generated question for chunk 143: What project focuses on India-specific localization needs within the context of AI transformation?\n",
            "Generated question for chunk 144: What are the key recommendations outlined in Section 7?\n",
            "Generated question for chunk 145: What company is the context referring to?\n",
            "Generated question for chunk 146: What is the goal for the number of Proofs of Concept (PoCs) to be moved to production in the context of Accelerate Agentic AI Monetization?\n",
            "Generated question for chunk 147: What types of industry-specific AI playbooks are being developed according to the context?\n",
            "Generated question for chunk 148: What initiative is being proposed to enhance AI talent development?\n",
            "Generated question for chunk 149: What role does Tech Mahindra aim to play in the AI partner ecosystem?\n",
            "Generated question for chunk 150: What project is being used internally to transform AI practices and serve as a case study for responsible AI?\n",
            "Generated question for chunk 151: What information is provided for individuals considering employment opportunities?\n",
            "Generated question for chunk 152: What fields are highlighted as strong opportunities in the context provided?\n",
            "Generated question for chunk 153: What is the deadline for mandatory AI reskilling to ensure career growth?\n",
            "Generated question for chunk 154: What type of policies support work-life balance?\n",
            "Generated question for chunk 155: What types of sectors are experiencing exposure to cutting-edge AI?\n",
            "Generated question for chunk 156: What types of sources are included in the appendix for data and references?\n",
            "Generated question for chunk 157: What date was the Q2 FY'26 results for Tech Mahindra reported?\n",
            "Generated question for chunk 158: What information can be found in the \"Contact & Further Information\" section?\n",
            "Generated question for chunk 159: What is the stock symbol for Tech Mahindra Limited?\n",
            "Generated question for chunk 160: What is the website to visit for information on AI services provided by Tech Mahindra?\n",
            "Generated question for chunk 161: What is the next scheduled update for the report?\n",
            "Generated question for chunk 162: What sources were used to compile the information in the report?\n",
            "\n",
            "Total 162 questions generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12c1184a"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to iterate through the `generated_questions` and use the `call_rag_chain` function to find answers for each question. The questions and their answers will then be compiled into `document_qa_pairs`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7edabec",
        "outputId": "7c62d450-a5e6-49eb-c1e2-54d1f3367555"
      },
      "source": [
        "sample_generated_questions = []\n",
        "\n",
        "for i, split in enumerate(splits[:5]):\n",
        "    question = question_gen_chain.invoke(split.page_content)\n",
        "    sample_generated_questions.append(question)\n",
        "    print(f\"Generated question for chunk {i+1}: {question}\")\n",
        "\n",
        "print(f\"\\nTotal {len(sample_generated_questions)} sample questions generated.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated question for chunk 1: What is the primary focus of Tech Mahindra's business operations?\n",
            "Generated question for chunk 2: What is the employee count mentioned in the context?\n",
            "Generated question for chunk 3: What is the primary focus of the report for Tech Mahindra Limited in December 2025?\n",
            "Generated question for chunk 4: What is the main purpose of the Executive Summary?\n",
            "Generated question for chunk 5: What is the number of professionals employed by Tech Mahindra?\n",
            "\n",
            "Total 5 sample questions generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e4f9c27",
        "outputId": "0c50d8ad-4562-41c6-8eee-060f3ab131ae"
      },
      "source": [
        "sample_qa_pairs = []\n",
        "inputs=[]\n",
        "outputs=[]\n",
        "\n",
        "for question in sample_generated_questions:\n",
        "    # Use the existing call_rag_chain function to get the answer\n",
        "    answer = call_rag_chain(question)\n",
        "    inputs.append({\"question\": question})\n",
        "    outputs.append({\"output\": answer})\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the primary focus of Tech Mahindra's business operations?\n",
            "A: I don't have enough information.\n",
            "Q: What is the employee count mentioned in the context?\n",
            "A: The employee count mentioned in the context is as follows:\n",
            "- Total Headcount: 119,343 employees (as of March 31, 2025)\n",
            "- Total Headcount (FY'25): 148,731 employees (full fiscal year average)\n",
            "- Total Headcount (Q2 FY'26): 152,714 employees (as of September 30, 2025)\n",
            "- IT Services Headcount: 78,528 employees (Q2 FY'26)\n",
            "- BPS/Sales/Support Staff: ~74,186 employees (remaining headcount)\n",
            "Q: What is the primary focus of the report for Tech Mahindra Limited in December 2025?\n",
            "A: The primary focus of the report for Tech Mahindra Limited in December 2025 is on HR Policies, Workforce Metrics, and Strategic AI Direction.\n",
            "Q: What is the main purpose of the Executive Summary?\n",
            "A: I don't have enough information.\n",
            "Q: What is the number of professionals employed by Tech Mahindra?\n",
            "A: Tech Mahindra employs 150,000+ professionals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6Hu0P_HcxbQ",
        "outputId": "63a29b17-c7e0-4bfd-9977-3d5c13832c94"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': \"What is the primary focus of Tech Mahindra's business operations?\"},\n",
              " {'question': 'What is the employee count mentioned in the context?'},\n",
              " {'question': 'What is the primary focus of the report for Tech Mahindra Limited in December 2025?'},\n",
              " {'question': 'What is the main purpose of the Executive Summary?'},\n",
              " {'question': 'What is the number of professionals employed by Tech Mahindra?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZjlj1oCfOoU",
        "outputId": "80cead02-0827-40bb-a066-e6a6a8e032a7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'output': \"I don't have enough information.\"},\n",
              " {'output': \"The employee count mentioned in the context is as follows:\\n- Total Headcount: 119,343 employees (as of March 31, 2025)\\n- Total Headcount (FY'25): 148,731 employees (full fiscal year average)\\n- Total Headcount (Q2 FY'26): 152,714 employees (as of September 30, 2025)\\n- IT Services Headcount: 78,528 employees (Q2 FY'26)\\n- BPS/Sales/Support Staff: ~74,186 employees (remaining headcount)\"},\n",
              " {'output': 'The primary focus of the report for Tech Mahindra Limited in December 2025 is on HR Policies, Workforce Metrics, and Strategic AI Direction.'},\n",
              " {'output': \"I don't have enough information.\"},\n",
              " {'output': 'Tech Mahindra employs 150,000+ professionals.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "# TODO: Fill in dataset id\n",
        "dataset_id = \"9eaf0f90-ff46-4f8f-ae95-53c256e85303\"\n",
        "\n",
        "client.create_examples(\n",
        "  inputs=inputs,\n",
        "  outputs=outputs,\n",
        "  dataset_id=dataset_id,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r_5uWg3duf7",
        "outputId": "1064f9f6-b037-420b-a35f-17b0712433f1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'example_ids': ['183b139d-a28e-4861-ae09-5dd6b11e7b11',\n",
              "  '23372580-6bed-4b42-97eb-3caf6f550ec3',\n",
              "  '6e164287-8079-4cc2-a6f1-e07f6aa806ca',\n",
              "  '023638d5-a166-4d03-9360-c9f07f15c8ad',\n",
              "  '520f01fa-9b0b-4bb9-a5d5-f53925124ce0'],\n",
              " 'count': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.structured_output import ToolStrategy"
      ],
      "metadata": {
        "id": "80FTDVwCNCnn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt=\"\"\"You are a semantic similarity evaluator. Compare the meanings of two responses to a question, \"\n",
        "                    \"Reference Response and New Response, where the reference is the correct answer, and we are trying to judge if the new response is similar. \"\n",
        "                    \"Provide a score between 1 and 10, where 1 means completely unrelated, and 10 means identical in meaning.\"\"\""
      ],
      "metadata": {
        "id": "oGgk6LtiNZDQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class Similarity_Score(BaseModel):\n",
        "    similarity_score: int = Field(description=\"Semantic similarity score between 1 and 10, where 1 means unrelated and 10 means identical.\")\n"
      ],
      "metadata": {
        "id": "PH6PmBgcNvrG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent= create_agent(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    system_prompt=eval_prompt,\n",
        "    response_format=ToolStrategy(Similarity_Score)\n",
        ")"
      ],
      "metadata": {
        "id": "cEQTQaoyNIDs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aViCqfy6OeAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KIzKco__Onj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "class Similarity_Score(BaseModel):\n",
        "    similarity_score: int = Field(description=\"Semantic similarity score between 1 and 10, where 1 means unrelated and 10 means identical.\")\n",
        "\n",
        "# NOTE: This is our evaluator\n",
        "def compare_semantic_similarity(inputs: dict, reference_outputs: dict, outputs: dict):\n",
        "    input_question = inputs[\"question\"]\n",
        "    reference_response = reference_outputs[\"output\"]\n",
        "    run_response = outputs[\"output\"]\n",
        "\n",
        "    agent= create_agent(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    system_prompt=eval_prompt,\n",
        "    response_format=ToolStrategy(Similarity_Score)\n",
        "    )\n",
        "    result=agent.invoke({\"role\": \"user\", \"content\": f\"Question: {input_question}\\n Reference Response: {reference_response}\\n Run Response: {run_response}\"})\n",
        "\n",
        "    return {\"score\": result['structured_response'].similarity_score, \"key\": \"similarity\"}\n"
      ],
      "metadata": {
        "id": "2Fn5W_9Vjjon"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From Dataset Example\n",
        "inputs = {\n",
        "  \"question\": \"What is the primary focus of the report for Tech Mahindra Limited in December 2025?\"\n",
        "}\n",
        "reference_outputs = {\n",
        "  \"output\": \"Majority of concentration for Tech Mahindra Limited in December 2025 is on HR Policies, Workforce Metrics, and Strategic AI Direction.\"\n",
        "}\n",
        "\n",
        "\n",
        "# From Run\n",
        "outputs = {\n",
        "  \"output\": \"The primary focus of the report for Tech Mahindra Limited in December 2025 is on HR Policies, Workforce Metrics, and Strategic AI Direction\"\n",
        "}"
      ],
      "metadata": {
        "id": "mWc2oZA8Pfbw"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_semantic_similarity(inputs,reference_outputs,outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ub7__9SQOlL",
        "outputId": "59a3abd9-e74e-4845-8e41-23f080504da3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 8, 'key': 'similarity'}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_semantic_similarity_eval(reference_outputs: dict, outputs: dict):\n",
        "    input_question = inputs[\"question\"]\n",
        "    reference_response = reference_outputs[\"output\"]\n",
        "    run_response = outputs[\"output\"]\n",
        "\n",
        "    agent= create_agent(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    system_prompt=eval_prompt,\n",
        "    response_format=ToolStrategy(Similarity_Score)\n",
        "    )\n",
        "    result=agent.invoke({\"role\": \"user\", \"content\": f\"Question: {input_question}\\n Reference Response: {reference_response}\\n Run Response: {run_response}\"})\n",
        "\n",
        "    return {\"score\": result['structured_response'].similarity_score, \"key\": \"similarity\"}"
      ],
      "metadata": {
        "id": "kJxIdAnlX3DG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import evaluate, Client\n",
        "\n",
        "client = Client()\n",
        "dataset_name = \"techm_rag_golden_dataset\"\n",
        "\n",
        "def is_concise_enough(reference_outputs: dict, outputs: dict) -> dict:\n",
        "    score = len(outputs[\"output\"]) < 1.5 * len(reference_outputs[\"output\"])\n",
        "    return {\"key\": \"is_concise\", \"score\": int(score)}\n",
        "\n",
        "def target_function(inputs: dict):\n",
        "    return call_rag_chain(inputs[\"question\"])\n",
        "\n",
        "evaluate(\n",
        "    target_function,\n",
        "    data=dataset_name,\n",
        "    evaluators=[is_concise_enough],\n",
        "    experiment_prefix=\"gpt-4o-mini\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848,
          "referenced_widgets": [
            "57173f4c12b04361990e16e3c9db7cf4",
            "46135cc26514417b89482e514885af6c",
            "00b99e0db01048feaae8568ba27463fd",
            "791a21f96ddc4d188f513d369310b3e1",
            "c272b2c65c674496a5fb9c688c704f0f",
            "55df3ce96eb044e8a2f04d9aafee759a",
            "1a61b69e63cf434b9b065002761bcbb5",
            "69e4fdce69e94ff3a3a4284d35ad6a0d",
            "5c04b916058940ef86546b24688855e4",
            "9e27a7d2ac1a4672a7ba3f671cedf2e6",
            "6173129e0dab49d1a823b6e50c85b330"
          ]
        },
        "id": "P1akT9taZb46",
        "outputId": "de21d926-69b1-40b1-b691-df4a4cb424ab"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for experiment: 'gpt-4o-mini-e4cd6201' at:\n",
            "https://smith.langchain.com/o/b14e6248-7eea-4871-b9cf-55af6d804596/datasets/9eaf0f90-ff46-4f8f-ae95-53c256e85303/compare?selectedSessions=bab61c2e-5e87-4b14-a08a-a2c9557c0a7e\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57173f4c12b04361990e16e3c9db7cf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the primary focus of Tech Mahindra's business operations?\n",
            "A: I don't have enough information.\n",
            "Q: What is the primary focus of the report for Tech Mahindra Limited in December 2025?\n",
            "A: The primary focus of the report for Tech Mahindra Limited in December 2025 is on HR Policies, Workforce Metrics, and Strategic AI Direction.\n",
            "Q: What is the main purpose of the Executive Summary?\n",
            "A: I don't have enough information.\n",
            "Q: What is the employee count mentioned in the context?\n",
            "A: The employee count mentioned in the context is as follows:\n",
            "- Total Headcount: 119,343 employees (as of March 31, 2025)\n",
            "- Total Headcount (FY'25): 148,731 employees (full fiscal year average)\n",
            "- Total Headcount (Q2 FY'26): 152,714 employees (as of September 30, 2025)\n",
            "- IT Services Headcount: 78,528 (Q2 FY'26)\n",
            "- BPS/Sales/Support Staff: ~74,186 (remaining headcount)\n",
            "Q: What is the number of professionals employed by Tech Mahindra?\n",
            "A: Tech Mahindra employs 150,000+ professionals.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ExperimentResults gpt-4o-mini-e4cd6201>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.output</th>\n",
              "      <th>feedback.is_concise</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the primary focus of Tech Mahindra's b...</td>\n",
              "      <td>I don't have enough information.</td>\n",
              "      <td>None</td>\n",
              "      <td>I don't have enough information.</td>\n",
              "      <td>1</td>\n",
              "      <td>1.320269</td>\n",
              "      <td>023638d5-a166-4d03-9360-c9f07f15c8ad</td>\n",
              "      <td>019af86f-2ccb-7533-b57d-c2bf4f71b0f6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the primary focus of the report for Te...</td>\n",
              "      <td>The primary focus of the report for Tech Mahin...</td>\n",
              "      <td>None</td>\n",
              "      <td>The primary focus of the report for Tech Mahin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.250385</td>\n",
              "      <td>183b139d-a28e-4861-ae09-5dd6b11e7b11</td>\n",
              "      <td>019af86f-31f9-7882-9dad-742e1d61db50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the main purpose of the Executive Summ...</td>\n",
              "      <td>I don't have enough information.</td>\n",
              "      <td>None</td>\n",
              "      <td>I don't have enough information.</td>\n",
              "      <td>1</td>\n",
              "      <td>1.259112</td>\n",
              "      <td>23372580-6bed-4b42-97eb-3caf6f550ec3</td>\n",
              "      <td>019af86f-36dd-74c1-87b0-61f7076a79d0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the employee count mentioned in the co...</td>\n",
              "      <td>The employee count mentioned in the context is...</td>\n",
              "      <td>None</td>\n",
              "      <td>The employee count mentioned in the context is...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.892527</td>\n",
              "      <td>520f01fa-9b0b-4bb9-a5d5-f53925124ce0</td>\n",
              "      <td>019af86f-3bcd-7a21-ba41-07cc1cd840ca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the number of professionals employed b...</td>\n",
              "      <td>Tech Mahindra employs 150,000+ professionals.</td>\n",
              "      <td>None</td>\n",
              "      <td>Tech Mahindra employs 150,000+ professionals.</td>\n",
              "      <td>1</td>\n",
              "      <td>1.106545</td>\n",
              "      <td>6e164287-8079-4cc2-a6f1-e07f6aa806ca</td>\n",
              "      <td>019af86f-471c-7130-b1ca-7c2893f41f55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}